A verifiable delay function (VDF) is a cryptographic primitive that takes a long time to compute, but produces
 a unique output that is efficiently and publicly verifiable.  <a href="https://doi.org/10.4230/LIPIcs.ICALP.2020.83">Mahmoody, Smith and Wu (ICALP 2020)</a> prove
  that VDFs satisfying both perfect completeness and adaptive perfect uniqueness do not exist in the random 
  oracle model. Moreover, <a href="https://doi.org/10.1007/978-3-030-45721-1_25">Ephraim, Freitag, Komargodski, and Pass  (EUROCRYPT 2020)</a> construct a VDF
   with perfect completeness and computational uniqueness, a much weaker guarantee compare to perfect uniqueness, 
   in the random oracle model under the repeated squaring assumption. In this work, we close the gap between 
   existing constructions and known lower bounds by showing that VDFs with imperfect completeness and 
   non-adaptive computational uniqueness cannot be constructed in the pure random oracle model (without 
   additional computational assumptions).